
# CONFIG FILE WITH EXAMPLE
##############################################################################

# Example: merging three datasets to identify features that relate to HDL
# Distances between samples are also included when creating delta datasets
# Config file prevents users from having to type a long command and they can
# plan analysis better
##############################################################################

# REQUIRED COLUMNS
# For now html output must be in the 
##############################################################################
analyst: "Jennifer Fouquier"
random_effect: "study_id"
sample_id: "sample_id"
timepoint: "timepoint"

# Analysis details
# TODO there are issues with keeping html output in same folder... fix later
# HDL-Demo.html output is in Snakefile Dir (run code from this directory)
##############################################################################
# TODO make the HDL-Name the same as the report name
out: "workflow-results/simulation/"
report_name: "simulation.html"
response_var: "happiness" # Variable you are trying to explain

# make interactive output of dataframes for interpretation (TRUE or FALSE)
build_datatable: "TRUE"

# Mixed-effects Random Forest (MERF) arguments
##############################################################################
# For analysis
#iterations: "20"
#n_estimators: "300"

# For testing (doing too few even for testing may cause failure)
iterations: "3"
n_estimators: "100"

borutaSHAP_trials: "20"
borutaSHAP_percentile: "100"

analysis_notes: "Simulation test no random vars"
# make interactive output of dataframes for interpretation (TRUE or FALSE)
enc_percent_threshold: "0"

# When creating deltas, are there distance matrices to include?
# Leave distance_matrices empty if not in use
##############################################################################
distance_matrices: "list()"

# PCA parameter lists
##############################################################################
# For all datasets you wish to perform PCA on, you must provide a list of lists
# Must include: pca_name (string), feature_list (c() vector),
# cum_var_thres (select dims that explain at least a certain percent variance
# Suggest naming PCA something like PCA_metabolic for interpretation

metadata_pca_list: "list()"

# All datasets used for analysis are included with the option to perform
# dimensionality reduction on them individually
# suggest naming each dataset clearly to improve interpretation (i.e. elisa,
# cytof, 'asvs', etc.)
# METHODS are: 'pca', 'scnic' or 'None'
#https://codebeautify.org/jsonviewer
##############################################################################


# These 4 vars are applied to full dataset after merging. For modifications
# on individual datasets, add lists to json below.
##############################################################################
drop_rows: "c()"
constrain_rows: "c()"
# Can only use one of the below variables (drop_cols or constrain_cols)
drop_cols: "c()"
constrain_cols: "c()"

# These are R lists of actions to take on individual datasets
# Must have a blank list if no dataset modifications are needed
"df_mod_no_action": "list(drop_rows=c(), constrain_rows=c(), drop_cols=c(), 
constrain_cols=c())"

"df_mod_metadata": "list(drop_rows=c(''), constrain_rows=c(), drop_cols=c(), 
constrain_cols=c())"

dataset_json: '{
  "datasets": {
    "test-data": {
      "file_path": "data/simulation/simulation.txt",
      "ds_param_dict": {
        "df_mod": "df_mod_no_action"
      },
      "dim_method": "None",
      "dim_param_dict": {
      }
    }
  }
}'