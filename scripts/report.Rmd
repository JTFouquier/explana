---
title: "Feature Selection Report"
date: "`r Sys.Date()`"
params:
   rmd: "report.Rmd"
output:
  html_document
---

```{r setup, include=FALSE}
source("scripts/install.R")
# source("scripts/feature-heatmaps.R")
source("scripts/colors.R")
package_list <- c("knitr", "kableExtra", "htmltools", "tidyverse",
"Hmisc", "jsonlite")
install_r_packages(package_list = package_list)
library(knitr)
library(htmltools)
library(tidyverse)
library(Hmisc)
library(jsonlite)
library(kableExtra)

knitr::opts_chunk$set(echo = FALSE,
                      eval = TRUE)
```

```{r comment="", echo = FALSE}

response_var <- snakemake@config[["response_var"]]
random_effect <- snakemake@config[["random_effect"]]

drop_cols <- snakemake@config[["drop_cols"]]
drop_rows <- snakemake@config[["drop_rows"]]
constrain_rows <- snakemake@config[["constrain_rows"]]
constrain_cols <- snakemake@config[["constrain_cols"]]

iterations <- snakemake@config[["iterations"]]
n_estimators <- snakemake@config[["n_estimators"]]

borutashap_trials <- snakemake@config[["borutaSHAP_trials"]]
borutashap_percentile <- snakemake@config[["borutaSHAP_percentile"]]

enc_percent_threshold <- snakemake@config[["enc_percent_threshold"]]

out_path <- snakemake@config[["out"]]
original_path <- paste0(out_path, snakemake@config[["path_rf_original"]])
first_path <- paste0(out_path, snakemake@config[["path_rf_first"]])
previous_path <- paste0(out_path, snakemake@config[["path_rf_previous"]])
pairwise_path <- paste0(out_path, snakemake@config[["path_rf_pairwise"]])

wd <- paste0(getwd(), "/")
wd_analysis <- paste0(wd, out_path)
wd_original <- paste0(wd, original_path)
wd_first <- paste0(wd, first_path)
wd_previous <- paste0(wd, previous_path)
wd_pairwise <- paste0(wd, pairwise_path)

pretty_table <- function(dataset_type, out_path, display_file) {
  df <- paste0(out_path,
  snakemake@config[[paste0("path_rf_", dataset_type)]],
  paste0(dataset_type, display_file))
  # cat(readLines(df), sep = "\n")
  df <- read.csv(df, sep = "\t", check.names = FALSE)

  kable(df, format = "html", escape = FALSE) %>%
    kable_styling()
}

url_tables <- function(df_in) {
  df <- read.csv(df_in, sep = "\t", check.names = FALSE)

  df$url <- lapply(df$url, function(url) {
    as.character(a(href = url, target = "_blank", url))
  })

  df_table <- df %>%
    mutate(url = cell_spec(url, "html", escape = FALSE))

  kable(df_table, format = "html", escape = FALSE) %>%
    kable_styling()
}
```

```{r include = FALSE }

plot_pattern_display <- function(path_name, pattern, grep_arg) {
  files <- list.files(path = path_name, pattern = pattern)
  my_plots <- grep(grep_arg, files, value = TRUE)

  # get files with pattern and grep argument
  for (f in my_plots) {
      cat("\n\n")
      cat(paste0("![](", path_name, f, ")"), "\n")
  }
}

# create the plot to show which datasets important features
# were occurring in (done now after building all models)
# make_feature_heatmaps(out_path)


# after variables are encoded, remove very low occurring ones if wanted.
if (enc_percent_threshold == "0") {

  enc_percent_threshold_print <- paste0("low occuring or rare categorical",
  " variables were not removed")

} else {

  enc_percent_threshold_print <- paste0("low occurring or rare categorical values were removed if found in less than ", enc_percent_threshold, "% of samples") # nolint

}


```

#### Analyst: `r toString(snakemake@config[["analyst"]])`

***

<h1 style="background-color:`r color_summary`; color: black; text-align: center; padding-top:20px; padding-bottom: 20px; padding-left: 20px;">Summary</h1>

### Analysis Description:

#### `r toString(snakemake@config[["analysis_notes"]])`

***

### Inputs and Analytic Decisions {.tabset}

#### Analysis Summary

**Response variable:** ``r response_var``

**Random effect:** ``r random_effect``

**Features dropped:** ``r toString(drop_cols)``

**Values dropped (feature & value):** ``r toString(drop_rows)``

**Constrained to rows:** ``r toString(constrain_rows)``

#### Datasets

```{r comment=""} 
snakemake@config[["dataset_json"]] %>%
  toJSON %>%
  prettify()

print(snakemake@config[["originaloob_all_features"]])
# cat(snakemake@config[["originaloob_all_features"]])
```

#

***

### Summary of methods

This workflow (name needed!) was used to identify important features 
predictive of the response variable, **``r response_var``**.

Categorical variables were encoded (expand!!!!! TODO) and **``r enc_percent_threshold_print``**.

A random effect 
of **``r random_effect``** was used to adjust for non-independence 
(repeated measurements) as needed. There were 
**``r n_estimators` trees`** used per Random Forest model. If mixed 
effects Random Forests were needed, **``r iterations` iterations`** 
were performed. BorutaSHAP was used with 
**``r borutashap_trials` trials`** and features were considered 
important if they performed better than shuffled features
**``r borutashap_percentile`%`** of the time.

Values of the response variable, **``r response_var``**, are 
explained best with the important features selected using this 
workflow.

Please ensure you understand the workflow and that the percent 
variation explained for each model is adequate for your purposes. 
When you are using all your data without prior hypotheses, you 
are performing *exploratory analysis* and should make this clear
when discussing results.

This workflow is designed to assist with understanding 
original feature values, as well as changes in feature 
values, when compared to various reference points. 
Certain features may carry varying degrees of importance 
across different datasets and this workflow helps 
identify these discrepancies.

Additional figures and files can be found in output directory.

***

### Directory Links

[⇨ Full Analysis Directory](file://`r wd_analysis`){target="_blank"}

[⇨ Original Dataset    |  ](file://`r wd_original`){target="_blank"}
[⇨ First Delta Dataset    |  ](file://`r wd_first`){target="_blank"}
[⇨ Previous Delta Dataset    |  ](file://`r wd_previous`){target="_blank"}
[⇨ Pairwise Delta Dataset](file://`r wd_pairwise`){target="_blank"}

***

### Results Summary {.tabset}

#### Selected Feature Occurences by Dataset

```{r fig.align = "center"}
include_graphics(paste0(out_path, "important-feature-occurrences.svg"))
```

#### Interpretation/Literature Search

```{r}
url_tables(snakemake@input[["urls"]])
```

#

***

<h1 style="background-color:`r color_original`; color: black; text-align: center; padding-top:20px; padding-bottom: 20px; padding-left: 20px;">Original Dataset</h1>

[⇨ Open File Directory](file://`r wd_original`){target="_blank"}

## Results {.tabset}

### Log and SHAP Summary

```{r comment=""}
cat(readLines(snakemake@input[["original_log"]]), sep = "\n")
```


```{r results="asis", comment=""}
plot_pattern_display(path_name = original_path, pattern = ".svg",
                     grep_arg = "SHAP-summary-beeswarm")
```

### Selected Features

```{r out.width = 1000, out.height = 600, comment=""}
pretty_table("original", out_path, "-boruta-important.txt")
```

### Input Features

```{r out.width = 1000, out.height = 600, comment=""}
pretty_table("original", out_path, "-input-features.txt")
```

### BorutaSHAP

```{r results="asis", comment=""}
plot_pattern_display(path_name = original_path, pattern = ".svg",
                     grep_arg = "boruta-accepted")
```

### Figures

[⇨ Open PDF in new window](file://`r wd_original`original.pdf){target="_blank"}

```{r out.width = 1100, out.height = 600, comment=""}
include_graphics(paste0(original_path, "original.pdf"))
```

### Interpretation/Literature Search

```{r}
url_tables(paste0(original_path, "original-urls.txt"))
```

#

***

<h1 style="background-color:`r color_first`; color: black; text-align: center; padding-top:20px; padding-bottom: 20px; padding-left: 20px;">First Delta Dataset</h1>

[⇨ Open File Directory](file://`r wd_first`){target="_blank"}

## Results {.tabset}

### Log and SHAP Summary

```{r out.width = 1000, out.height = 600, comment=""}
cat(readLines(snakemake@input[["first_log"]]), sep = "\n")
```

```{r results="asis", comment=""}
plot_pattern_display(path_name = first_path, pattern = ".svg",
                     grep_arg = "SHAP-summary-beeswarm")
```

### Selected Features

```{r out.width = 1000, out.height = 600, comment=""}
pretty_table("first", out_path, "-boruta-important.txt")
```

### Input Features

```{r out.width = 1000, out.height = 600, comment=""}
pretty_table("first", out_path, "-input-features.txt")
```

### BorutaSHAP

```{r results="asis", comment=""}
plot_pattern_display(path_name = first_path, pattern = ".svg",
                     grep_arg = "boruta-accepted")
```

### Figures

[⇨ Open PDF in new window](file://`r wd_first`first.pdf){target="_blank"}

```{r out.width = 1100, out.height = 600, comment=""}
include_graphics(paste0(first_path, "first.pdf"))
```

### Interpretation/Literature Search

```{r}
url_tables(paste0(first_path, "first-urls.txt"))
```

#

***

<h1 style="background-color:`r color_previous`; color: black; text-align: center; padding-top:20px; padding-bottom: 20px; padding-left: 20px;">Previous Delta Dataset</h1>

[⇨ Open File Directory](file://`r wd_previous`){target="_blank"}

## Results {.tabset}

### Log and SHAP Summary

```{r out.width = 1100, out.height = 600, comment=""}
cat(readLines(snakemake@input[["previous_log"]]), sep = "\n")
```

```{r results="asis", comment=""}
plot_pattern_display(path_name = previous_path, pattern = ".svg",
                     grep_arg = "SHAP-summary-beeswarm")
```

### Selected Features

```{r out.width = 1000, out.height = 600, comment=""}
pretty_table("previous", out_path, "-boruta-important.txt")
```

### Input Features

```{r out.width = 1000, out.height = 600, comment=""}
pretty_table("previous", out_path, "-input-features.txt")
```

### BorutaSHAP

```{r results="asis", comment=""}
plot_pattern_display(path_name = previous_path, pattern = ".svg",
                     grep_arg = "boruta-accepted")
```

### Figures

[⇨ Open PDF in new window](file://`r wd_previous`previous.pdf){target="_blank"}

```{r out.width = 1000, out.height = 600, comment=""}
include_graphics(paste0(previous_path, "previous.pdf"))
```

### Interpretation/Literature Search

```{r}
url_tables(paste0(previous_path, "previous-urls.txt"))
```

#
***

<h1 style="background-color:`r color_pairwise`; color: black; text-align: center; padding-top:20px; padding-bottom: 20px; padding-left: 20px;">Pairwise Delta Dataset</h1>

[⇨ Open File Directory](file://`r wd_pairwise`){target="_blank"}

## Results {.tabset}

### Log and SHAP Summary

```{r out.width = 1000, out.height = 600, comment=""}
cat(readLines(snakemake@input[["pairwise_log"]]), sep = "\n")
```

```{r results="asis", comment=""}
plot_pattern_display(path_name = pairwise_path, pattern = ".svg",
                     grep_arg = "SHAP-summary-beeswarm")
```

### Selected Features

```{r out.width = 1000, out.height = 600, comment=""}
pretty_table("pairwise", out_path, "-boruta-important.txt")
```

### Input Features

```{r out.width = 1000, out.height = 600, comment=""}
pretty_table("pairwise", out_path, "-input-features.txt")
```

### BorutaSHAP

```{r results="asis", comment=""}
plot_pattern_display(path_name = pairwise_path, pattern = ".svg",
                     grep_arg = "boruta-accepted")
```

### Figures

[⇨ Open PDF in new window](file://`r wd_pairwise`pairwise.pdf){target="_blank"}

```{r out.width = 1000, out.height = 600, comment=""}
include_graphics(paste0(pairwise_path, "pairwise.pdf"))
```

### Interpretation/Literature Search

```{r}
url_tables(paste0(pairwise_path, "pairwise-urls.txt"))
```

#

***

#

<h1 style="background-color:lightgray; color: black; text-align: center; padding-top:20px; padding-bottom: 20px; padding-left: 20px;">Post-hoc tests</h1>

# Results {.tabset}

***

## Description

Linear models or linear mixed effects models were used for post hoc testing to determine if a linear relationship exists between selected feature and response variable.

## Results

```{r out.width = 1100, out.height = 600, comment=""}
# htmltools::includeHTML(snakemake@input[["post_hoc"]])
```

## Graphs

```{r out.width = 1100, out.height = 600, comment=""}
# include_graphics(snakemake@input[["post_hoc_viz"]])
```


***

See the [Github repository](https://github.com/JTFouquier/snakemake-MERF "Still a work in progress!! :) ") for more information.

***

```{r}
# read in a table example
# df = read.csv(snakemake@input[["table_boruta"]], sep = "\t")
# knitr::kable(df$important_features, format = "html")
```

<a download="report.Rmd" href="`r base64enc::dataURI(file = params$rmd, mime="text/rmd", encoding="base64")`">Click here for R Markdown source file</a>

